System Message:
"""
Welcome to the AI Documentation Assistant! Your task is to create a comprehensive step-by-step documentation for an application based on the provided code and details. You will assist developers in understanding the application's functionality, structure, and code implementation. Begin by analyzing the code and identifying key components, modules, and dependencies. Break down the application's features and functionalities into logical sections for easy comprehension. Provide clear explanations, code snippets, and examples to illustrate how different parts of the application work. Ensure that the documentation covers installation instructions, usage guidelines, and any necessary prerequisites. Organize the documentation in a user-friendly format, including an introduction, architecture overview, API reference, and troubleshooting guide. Your role is to be an informative and reliable resource, guiding developers through the documentation creation process. Let's create a comprehensive documentation together!
"""

<!-- 
Application Information:  
"""  
Application Name: Adapt Payoff Letter Generator  
&nbsp;  
About application:  
```  
The main aim of this application is to generate the payoff letter by extracting the important details from Note Purchase and Guarantee Agreement provided by user. The details extraction process is backed by an Intelligent Research Based approach named ADAPT whose task is to intellegently automate the details extraction process.  
```  
&nbsp;  
---  
&nbsp;  
Application folder Structure:  
```  
/Adapt_Payoff_Generator_deployment  
|-- /documents                          # Folder to save the Note Purchase and Guarentee Agreement (NPGA) Document uploaded by user.  
|-- /metadata_extract_and_index         # Module responsible for extracting metadata.  
|   |-- __init__.py                     # __init__.py file  
|   |-- LDA_metadata_extract.py         # Metadata extraction Code  
|-- /SchemaExtractor                    # Module responsible for extracting NPGA document Schema   
|   |-- __init__.py                     # __init__.py file  
|   |-- schema_extractor.py             # document schema extraction code  
|-- /vector_store                       # folder to save the vector store of NPGA document  
|-- Adapt_verified_payoff_letter.txt    # File to save generated letter.  
|-- app_secrets.py                      # contains api key and endpoints of LLM  
|-- controller.py                       # Part of Adapt automation system that controls the planner and executor  
|-- doc_uploader.py                     # UI file where user interacts and uploads their respective NPGA  
|-- document_schema.txt                 # File to store Extracted document schema   
|-- execution_log.txt                   # File to store Adapt automation system execution log  
|-- executor.py                         # Another part of Adapat automation system responsible for executing each step of plan generated by planner  
|-- extracted_data.txt                  # File to save extracted data using Adapt system  
|-- letter_generator.py                 # File that consume extracted data and generates payoff letter using template  
|-- planner.py                          # Another part of Adapt automation system responsible for creating plan  
|-- prompt.py                           # Prompts to configure the LLM  
|-- template.py                         # template used by LLM to generate payoff letter  
|-- tools_description.py                # description of all the tools defined for LLM  
|-- requirements.txt                    # application dependencies  
&nbsp;  
```  
&nbsp;  
---  
&nbsp;  
Application Workflow:  
```  
`doc_uploader.py` is main file and it takes NPGA document from user and the document is saved in `documents` folder.  
After that `schema_extractor.py` is called to extract schema of the document and is saved inside `document_schema.txt` file.  
Next the Signature page from the document is extracted and is saved inside `extracted_data.txt` file.  
Next the metadata extraction and vector store creation is initiated and `LDA_metadata_extract.py` is called and it extracts the metadata and creates the vector store which is then stored in `vector_store` folder.  
Next Adapt autonomous details extraction process is initiated in which the `controller.py` is executed which further creates a plan using `planner.py` and execute the plan using `executor.py`. All the adapt execution log is stored inside `execution_log.txt` and extracted data is appended in `extracted_data.txt` file.  
After details extraction the `letter_generator.py` is executed which consumes the `extracted_data.txt` file and generates the Payoff letter by using the `template.py`.   
Finally the generated payoff letter is saved inside the `Adapt_verified_payoff_letter.txt` file and can be downloaded by the user from UI.  
```  
"""  
&nbsp;  
Documentation Structure:  
```  
## Adapt Payoff Letter Generator Documentation    
     
### Introduction    
- Overview of the Adapt Payoff Letter Generator    
- Purpose and target audience    
- Core features and benefits    
     
### Getting Started    
- Prerequisites    
  - Software requirements    
  - System requirements    
- Installation Instructions    
  - Step-by-step guide to setting up the application    
  - Installing dependencies from `requirements.txt`    
     
### Application Folder Structure    
- Detailed explanation of the folder structure and file organization    
     
### Application Workflow    
- Overview of the end-to-end process    
- Detailed explanation of the workflow steps    
     
### Modules and Code Explanation    
- `doc_uploader.py`    
  - Functionality and user interaction details    
- `schema_extractor.py`    
  - Schema extraction process explanation    
- `LDA_metadata_extract.py`    
  - Metadata extraction and vector store creation details    
- `controller.py`, `planner.py`, and `executor.py`    
  - Description of the ADAPT automation system components    
- `letter_generator.py`    
  - Payoff letter generation process    
     
### Usage Guide    
- How to run the application    
- Uploading a document and generating a payoff letter    
- Downloading the generated payoff letter    
     
### API Reference    
- `app_secrets.py`    
  - Description of API keys and endpoints (Note: Do not include actual keys in the documentation)    
- `prompt.py`    
  - Configuration prompts for the LLM    
- `template.py`    
  - Template management for letter generation    
- `tools_description.py`    
  - Description of the LLM tools    
     
### Contact and Support    
- How to get help or contribute to the project    
```  
&nbsp;  
By following above documentation structure lets create a documentation for the application section by section.  
&nbsp;  
Now, create Introduction section of the documentation. -->



<!-- 
Application Information:  
"""  
Application Name: Payoff Letter Generator with Document Agent

About application:
```
The main aim of this application is to generate the payoff letter by extracting the important details from Note Purchase and Guarantee Agreement provided by user. The details extraction process is backed by an Intelligent Document Agent whose task is to intellegently automate the details extraction process.
```

---

Application folder Structure:
```
/Adapt_Payoff_Generator_deployment
|-- /documents                          # Folder to save the Note Purchase and Guarentee Agreement (NPGA) Document uploaded by user.
|-- /metadata_extract_and_index         # Module responsible for extracting metadata.
|   |-- __init__.py                     # __init__.py file
|   |-- LDA_metadata_extract.py         # Metadata extraction Code
|-- /SchemaExtractor                    # Module responsible for extracting NPGA document Schema 
|   |-- __init__.py                     # __init__.py file
|   |-- schema_extractor.py             # document schema extraction code
|-- /vector_store                       # folder to save the vector store of NPGA document
|-- Adapt_verified_payoff_letter.txt    # File to save generated letter.
|-- app_secrets.py                      # contains api key and endpoints of LLM
|-- doc_agent.py                        # An intelligent document agent which automates the details extraction process
|-- doc_uploader.py                     # UI file where user interacts and uploads their respective NPGA
|-- document_schema.txt                 # File to store Extracted document schema 
|-- extracted_data.txt                  # File to save extracted data using Adapt system
|-- letter_generator.py                 # File that consume extracted data and generates payoff letter using template
|-- prompt.py                           # Prompts to configure the LLM
|-- template.py                         # template used by LLM to generate payoff letter
|-- tools_description.py                # description of all the tools defined for LLM
|-- requirements.txt                    # application dependencies

```

---

Application Workflow:
```
`doc_uploader.py` is main file and it takes NPGA document from user and the document is saved in `documents` folder.
After that `schema_extractor.py` is called to extract schema of the document and is saved inside `document_schema.txt` file.
Next the Signature page from the document is extracted and is saved inside `extracted_data.txt` file.
Next the metadata extraction and vector store creation is initiated and `LDA_metadata_extract.py` is called and it extracts the metadata and creates the vector store which is then stored in `vector_store` folder.
Next the `doc_agent` is invoked and autonomous details extraction process is initiated in which the document agent performs the similarity search in vector store and if it gets the correct response then it update the result in `extracted_data.txt` file else it performs query transformation and again searches the vector store. And this process is repeated till all the details are extracted.
After details extraction the `letter_generator.py` is executed which consumes the `extracted_data.txt` file and generates the Payoff letter by using the `template.py`. 
Finally the generated payoff letter is saved inside the `Adapt_verified_payoff_letter.txt` file and can be downloaded by the user from UI.
```
"""

---
Documentation Structure:  
```
# Payoff Letter Generator with Document Agent  
   
## Introduction  
   
The Payoff Letter Generator is a sophisticated application designed to streamline the process of generating payoff letters from Note Purchase and Guarantee Agreement (NPGA) documents. By leveraging an Intelligent Document Agent, the application automates the extraction of key details from the provided documents, making the creation of payoff letters efficient and less prone to human error.  
   
## Documentation Structure  
   
2. **Overview**  
    2.1 Purpose of the Application  
    2.2 Key Objectives


3. **Application Workflow**  
    3.1 Step-by-Step Guide to the Payoff Letter Generation Process  
    3.2 Detailed Workflow Description  
   
   
5. **Usage**  
    5.1 How to Run the Application  
    5.2 User Interaction with the System  
   
6. **Conclusion**  
    - Final Thoughts and Future Work  
   
```

By following above documentation structure lets create a documentation for the application section by section.  

Now, create Overview section of the documentation.

 -->

Application Information:  
"""  
Application Name: Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self improvement functionality

About application:
```   
The Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self-improvement functionality is an advanced application designed to provide users with a seamless experience in querying an Azure Cosmos DB using natural language. By leveraging cutting-edge AI models, this app interprets user queries and generates corresponding NoSQL queries, enabling users to retrieve accurate information from the Cosmos DB.  
   
One unique feature of this application is its feedback and self-improvement functionality. Users have the option to provide feedback on the generated answers. If the generated answer is correct, users can provide positive feedback, helping the system learn and reinforce accurate responses. In case the generated answer is incorrect or ambiguous, users can provide negative feedback along with the correct NoSQL database query. This feedback is then used to enhance the system's performance by testing and appending the user-provided NoSQL query to the vector store. As a result, the system continually improves and becomes more adept at generating accurate responses for similar natural language queries.  
   
With the Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self-improvement functionality, users can effortlessly interact with their Cosmos DB using natural language, while contributing to the system's growth and accuracy through feedback. This application revolutionizes the way users interact with NoSQL databases, making it easier than ever to retrieve the information they need.
```

---

Application folder Structure:
```
/VannaAI_TOT
|-- /storage                            # Folder to save the vector store of text to NoSQL dataset from `train_data.py` file.
|-- cosmos_status.py                    # Provides current cosmosdb info like total_entries persona_list, name_list, email_list
|-- data_extractor.py                   # Creates vector store using text to NoSQL dataset from `train_data.py` and augment the prompt with similar NoSQL db queries by performing similarity search in Vector store  
|-- main.py                             # Contains Streamlit UI code and Assistant Logic that uses TOT agent to create NoSQL db query and tests it using `execute_query` tool.
|-- train_data.py                       # File contains Text to NOSQL dataset.
|-- app_secrets.py                      # contains api key and endpoints of LLM
|-- Prompt.py                           # Prompts to configure the LLM and TOT agent
|-- app_func_desc.py                    # description of all the tools defined for LLM and Cosmos db
|-- requirements.txt                    # application dependencies

```

---

Application Workflow:
```
On execution, first the vector store is created by `data_extractor.py` using text to NoSQL dataset from `train_data.py`.
`main.py` is the main file that interacts with user and takes Natural Language users query, performs similarity search in vector store and gets NoSQL associated to similar Natural Language query and then augments the NoSQL to AI Assistant's Prompt, then assistant having relevant context creates NoSQL db query using Tree Of Thought Agent and executes it in the cosmos database and retrieves the data. After retrieving the data from cosmos db the assistant then generates the answer to the user's Natural Language query. The NL answer is displayed on the Chat Interface. Users have the option to provide feedback on the generated answers. If the generated answer is correct, users can provide positive feedback, helping the system learn and reinforce accurate responses. In case the generated answer is incorrect or ambiguous, users can provide negative feedback along with the correct NoSQL database query. This feedback is then used to enhance the system's performance by testing and appending the user-provided NoSQL query to the vector store. As a result, the system continually improves and becomes more adept at generating accurate responses for similar natural language queries.
```
"""
---

Above is the information of my application.  
&nbsp;  
Now before starting the documentation, I will be sharing the code from each file so that you can understand the app in much more detailed manner.  
&nbsp;  
Do you understand?  


---
Documentation Structure:  
```
# Payoff Letter Generator with Document Agent  
   
## Introduction  
   
The Payoff Letter Generator is a sophisticated application designed to streamline the process of generating payoff letters from Note Purchase and Guarantee Agreement (NPGA) documents. By leveraging an Intelligent Document Agent, the application automates the extraction of key details from the provided documents, making the creation of payoff letters efficient and less prone to human error.  
   
## Documentation Structure  
   
1. **Overview**  
    1.1 Purpose of the Application  
    1.2 High-Level Workflow  


3. **Application Workflow**  
    3.1 Step-by-Step Guide to the Payoff Letter Generation Process  
    3.2 Detailed Workflow Description  
   
   
5. **Usage**  
    5.1 How to Run the Application  
    5.2 User Interaction with the System  
   
6. **Conclusion**  
    - Final Thoughts and Future Work  
   
```

By following above documentation structure lets create a documentation for the application section by section.  

Now, create Overview section of the documentation.






<!-- Now, review and understand the code in detail and generate the detailed workflow of this application. -->





All prompts data:

system:

"""

Welcome to the AI Documentation Assistant! Your task is to create a comprehensive step-by-step documentation for an application based on the provided code and details. You will assist developers in understanding the application's functionality, structure, and code implementation. Begin by analyzing the code and identifying key components, modules, and dependencies. Break down the application's features and functionalities into logical sections for easy comprehension. Provide clear explanations, code snippets, and examples to illustrate how different parts of the application work. Ensure that the documentation covers installation instructions, usage guidelines, and any necessary prerequisites. Organize the documentation in a user-friendly format, including an introduction, architecture overview, API reference, and troubleshooting guide. Your role is to be an informative and reliable resource, guiding developers through the documentation creation process. Let's create a comprehensive documentation together!

"""


User:

"""

Application Information:    
"""    
Application Name: Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self improvement functionality  
&nbsp;  
About application:  
```     
The Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self-improvement functionality is an advanced application designed to provide users with a seamless experience in querying an Azure Cosmos DB using natural language. By leveraging cutting-edge AI models, this app interprets user queries and generates corresponding NoSQL queries, enabling users to retrieve accurate information from the Cosmos DB.    
     
One unique feature of this application is its feedback and self-improvement functionality. Users have the option to provide feedback on the generated answers. If the generated answer is correct, users can provide positive feedback, helping the system learn and reinforce accurate responses. In case the generated answer is incorrect or ambiguous, users can provide negative feedback along with the correct NoSQL database query. This feedback is then used to enhance the system's performance by testing and appending the user-provided NoSQL query to the vector store. As a result, the system continually improves and becomes more adept at generating accurate responses for similar natural language queries.    
     
With the Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self-improvement functionality, users can effortlessly interact with their Cosmos DB using natural language, while contributing to the system's growth and accuracy through feedback. This application revolutionizes the way users interact with NoSQL databases, making it easier than ever to retrieve the information they need.  
```  
&nbsp;  
---  
&nbsp;  
Application folder Structure:  
```  
/VannaAI_TOT  
|-- /storage                            # Folder to save the vector store of text to NoSQL dataset from `train_data.py` file.  
|-- cosmos_status.py                    # Provides current cosmosdb info like total_entries persona_list, name_list, email_list  
|-- data_extractor.py                   # Creates vector store using text to NoSQL dataset from `train_data.py` and augment the prompt with similar NoSQL db queries by performing similarity search in Vector store    
|-- main.py                             # Contains Streamlit UI code and Assistant Logic that uses TOT agent to create NoSQL db query and tests it using `execute_query` tool.  
|-- train_data.py                       # File contains Text to NOSQL dataset.  
|-- app_secrets.py                      # contains api key and endpoints of LLM  
|-- Prompt.py                           # Prompts to configure the LLM and TOT agent  
|-- app_func_desc.py                    # description of all the tools defined for LLM and Cosmos db  
|-- requirements.txt                    # application dependencies  
&nbsp;  
```  
&nbsp;  
---  
&nbsp;  
Application Workflow:  
```  
On execution, first the vector store is created by `data_extractor.py` using text to NoSQL dataset from `train_data.py`.  
`main.py` is the main file that interacts with user and takes Natural Language users query, performs similarity search in vector store and gets NoSQL associated to similar Natural Language query and then augments the NoSQL to AI Assistant's Prompt, then assistant having relevant context creates NoSQL db query using Tree Of Thought Agent and executes it in the cosmos database and retrieves the data. After retrieving the data from cosmos db the assistant then generates the answer to the user's Natural Language query. The NL answer is displayed on the Chat Interface. Users have the option to provide feedback on the generated answers. If the generated answer is correct, users can provide positive feedback, helping the system learn and reinforce accurate responses. In case the generated answer is incorrect or ambiguous, users can provide negative feedback along with the correct NoSQL database query. This feedback is then used to enhance the system's performance by testing and appending the user-provided NoSQL query to the vector store. As a result, the system continually improves and becomes more adept at generating accurate responses for similar natural language queries.  
```  
"""  
---  
&nbsp;  
Above is the information of my application.    
&nbsp;    
Now before starting the documentation, I will be sharing the code from each file so that you can understand the app in much more detailed manner.    
&nbsp;    
Do you understand?  
"""


Assistant:

"""

Yes, I understand. You have an application named Text to NoSQL QnA over Cosmos DB (TOT Agent) with Feedback and self-improvement functionality. It's designed to take natural language queries and translate them into NoSQL queries for Cosmos DB, with a unique feedback loop for self-improvement. You've outlined the application's folder structure and workflow.  
   
Before proceeding with the documentation, you will provide the code from each file so that I can create detailed and accurate documentation for your application.  
   
Please go ahead and share the code from each file, and I'll analyze it to assist you with the documentation process.

"""































Here is the application code from each file:
"""

"""

Now understand the each concept of the application and generate the Introduction part of the documentation